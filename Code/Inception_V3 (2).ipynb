{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AI7JTat7vmqQ"
      },
      "outputs": [],
      "source": [
        "# INCEPTION V3 NEURAL NETWORK TO CLASSIFY IMAGES INTO ONE OF THE 10 DISTRACTIONS\n",
        "\n",
        "# The method to use and implement this model is outlined in the ReadMe file\n",
        "\n",
        "# Sources cited:\n",
        "# https://keras.io/guides/transfer_learning/\n",
        "# https://keras.io/api/applications/#usage-examples-for-image-classification-models\n",
        "# https://keras.io/api/data_loading/\n",
        "# https://medium.com/@italojs/saving-your-weights-for-each-epoch-keras-callbacks-b494d9648202\n",
        "# https://datascience.stackexchange.com/questions/104572/does-validation-split-in-tf-keras-preprocessing-image-dataset-from-directory-res\n",
        "# Code also borrowed from the solution of P-Set 2 (CAS CS 523, Deep Learning, Professor Sarah)\n",
        "\n",
        "# The dataset is located on the Google Drive, Link:\n",
        "# https://drive.google.com/drive/folders/1XQwlyOjZL0dPDbWagURrSqa1dC6rDkgW?usp=sharing\n",
        "\n",
        "# importing files and libraries\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import keras\n",
        "from keras.preprocessing.image import smart_resize\n",
        "from PIL import Image\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score , recall_score, f1_score\n",
        "from sklearn.metrics import top_k_accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReMkTc0mUL-T",
        "outputId": "bab68c17-91a2-4ab8-d4f7-7919173bd578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mounting Google drive\n",
        "# the dataset is stored on the drive\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmxymENON_N1"
      },
      "outputs": [],
      "source": [
        "#folder='/content/drive/MyDrive/CS523_Deep_Learning/Data/train/c'\n",
        "\n",
        "#filelist = glob.glob(folder + '0' + '/*.jpg')\n",
        "#train_images = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
        "#train_labels = np.zeros((train_images.shape[0],), dtype=int)\n",
        "\n",
        "#for i in range(1,10):\n",
        "#    folder_i = folder+str(i)\n",
        "#    filelist = glob.glob(folder_i + '/*.jpg')\n",
        "#    temp=np.array([np.array(Image.open(fname)) for fname in filelist])\n",
        "#    train_images = np.vstack((train_images, temp))\n",
        "#    train_labels = np.hstack((train_labels, np.zeros((temp.shape[0],), dtype=int) + i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b549A--aVzi_"
      },
      "outputs": [],
      "source": [
        "#folder='/content/drive/MyDrive/CS523_Deep_Learning/Data/TestData/c'\n",
        "\n",
        "#filelist = glob.glob(folder + '0' + '/*.jpg')\n",
        "#test_images = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
        "#test_labels = np.zeros((test_images.shape[0],), dtype=int)\n",
        "\n",
        "#for i in range(1,10):\n",
        "#    folder_i = folder+str(i)\n",
        "#    filelist = glob.glob(folder_i + '/*.jpg')\n",
        "#    temp=np.array([np.array(Image.open(fname)) for fname in filelist])\n",
        "#    test_images = np.vstack((test_images, temp))\n",
        "#    test_labels = np.hstack((test_labels, np.zeros((temp.shape[0],), dtype=int) + i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "467bNG5nteeK",
        "outputId": "f37a4b46-7705-4bdd-c709-4a1aa3b7a9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20405 files belonging to 10 classes.\n",
            "Using 18365 files for training.\n",
            "Found 20405 files belonging to 10 classes.\n",
            "Using 2040 files for validation.\n",
            "Found 2019 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Extracting training, validation and test data sets\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/drive/MyDrive/CS523_Deep_Learning/Data/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    validation_split=0.1,\n",
        "    subset='training',\n",
        "    image_size=(480, 640))\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/drive/MyDrive/CS523_Deep_Learning/Data/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    validation_split=0.1,\n",
        "    subset='validation',\n",
        "    image_size=(480, 640))\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/drive/MyDrive/CS523_Deep_Learning/Data/TestData',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    image_size=(480, 640))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX47mRF7bE2X",
        "outputId": "584d009f-c0d8-4e07-8e04-3531d0a63546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 480, 640, 3)]     0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 13, 18, 2048)      21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,911,210\n",
            "Trainable params: 2,108,426\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "574/574 [==============================] - 857s 1s/step - loss: 4.3847 - accuracy: 0.1155 - val_loss: 2.3005 - val_accuracy: 0.1093\n",
            "Epoch 2/8\n",
            "574/574 [==============================] - 158s 275ms/step - loss: 2.3020 - accuracy: 0.1185 - val_loss: 2.2468 - val_accuracy: 0.1500\n",
            "Epoch 3/8\n",
            "574/574 [==============================] - 158s 275ms/step - loss: 2.2992 - accuracy: 0.1155 - val_loss: 2.2999 - val_accuracy: 0.1093\n",
            "Epoch 4/8\n",
            "574/574 [==============================] - 158s 275ms/step - loss: 2.3016 - accuracy: 0.1113 - val_loss: 2.2998 - val_accuracy: 0.1093\n",
            "Epoch 5/8\n",
            "574/574 [==============================] - 158s 275ms/step - loss: 2.3002 - accuracy: 0.1140 - val_loss: 2.2996 - val_accuracy: 0.1093\n",
            "Epoch 6/8\n",
            "574/574 [==============================] - 158s 275ms/step - loss: 2.3007 - accuracy: 0.1119 - val_loss: 2.2996 - val_accuracy: 0.1093\n",
            "Epoch 7/8\n",
            "574/574 [==============================] - 158s 274ms/step - loss: 2.3030 - accuracy: 0.1107 - val_loss: 2.2996 - val_accuracy: 0.1093\n",
            "Epoch 8/8\n",
            "574/574 [==============================] - 158s 274ms/step - loss: 2.3019 - accuracy: 0.1119 - val_loss: 2.2996 - val_accuracy: 0.1093\n"
          ]
        }
      ],
      "source": [
        "# Inception V3 model with transfer learning\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(480, 640, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "inputs = keras.Input(shape=(480, 640, 3))\n",
        "\n",
        "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "inputs = scale_layer(inputs)\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x) \n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x) \n",
        "\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history=model.fit(train_ds, epochs=8, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeMJIG2bdhi3",
        "outputId": "af4be080-56f6-4099-f2a7-0e75d9de769d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 480, 640, 3)]     0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 13, 18, 2048)      21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,911,210\n",
            "Trainable params: 23,876,778\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "574/574 [==============================] - ETA: 0s - loss: 2.3001 - accuracy: 0.1123\n",
            "Epoch 1: loss improved from inf to 2.30013, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 585s 999ms/step - loss: 2.3001 - accuracy: 0.1123 - val_loss: 2.2437 - val_accuracy: 0.1515\n",
            "Epoch 2/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 1.9192 - accuracy: 0.2824\n",
            "Epoch 2: loss improved from 2.30013 to 1.91920, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 571s 993ms/step - loss: 1.9192 - accuracy: 0.2824 - val_loss: 1.3885 - val_accuracy: 0.4392\n",
            "Epoch 3/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.8820 - accuracy: 0.6708\n",
            "Epoch 3: loss improved from 1.91920 to 0.88205, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 571s 994ms/step - loss: 0.8820 - accuracy: 0.6708 - val_loss: 0.2562 - val_accuracy: 0.9417\n",
            "Epoch 4/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8938\n",
            "Epoch 4: loss improved from 0.88205 to 0.32875, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 570s 993ms/step - loss: 0.3287 - accuracy: 0.8938 - val_loss: 0.1211 - val_accuracy: 0.9686\n",
            "Epoch 5/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9494\n",
            "Epoch 5: loss improved from 0.32875 to 0.17378, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 571s 994ms/step - loss: 0.1738 - accuracy: 0.9494 - val_loss: 0.1036 - val_accuracy: 0.9706\n",
            "Epoch 6/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9617\n",
            "Epoch 6: loss improved from 0.17378 to 0.12776, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 570s 993ms/step - loss: 0.1278 - accuracy: 0.9617 - val_loss: 0.0759 - val_accuracy: 0.9824\n",
            "Epoch 7/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9739\n",
            "Epoch 7: loss improved from 0.12776 to 0.08426, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 571s 994ms/step - loss: 0.0843 - accuracy: 0.9739 - val_loss: 0.0973 - val_accuracy: 0.9789\n",
            "Epoch 8/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9751\n",
            "Epoch 8: loss improved from 0.08426 to 0.08384, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 570s 993ms/step - loss: 0.0838 - accuracy: 0.9751 - val_loss: 0.0636 - val_accuracy: 0.9848\n",
            "Epoch 9/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9809\n",
            "Epoch 9: loss improved from 0.08384 to 0.06430, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 572s 995ms/step - loss: 0.0643 - accuracy: 0.9809 - val_loss: 0.0841 - val_accuracy: 0.9779\n",
            "Epoch 10/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9876\n",
            "Epoch 10: loss improved from 0.06430 to 0.04339, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 571s 994ms/step - loss: 0.0434 - accuracy: 0.9876 - val_loss: 0.0420 - val_accuracy: 0.9907\n",
            "Epoch 11/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9868\n",
            "Epoch 11: loss did not improve from 0.04339\n",
            "574/574 [==============================] - 529s 921ms/step - loss: 0.0485 - accuracy: 0.9868 - val_loss: 0.0478 - val_accuracy: 0.9887\n",
            "Epoch 12/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9846\n",
            "Epoch 12: loss did not improve from 0.04339\n",
            "574/574 [==============================] - 529s 921ms/step - loss: 0.0557 - accuracy: 0.9846 - val_loss: 0.0447 - val_accuracy: 0.9902\n",
            "Epoch 13/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9922\n",
            "Epoch 13: loss improved from 0.04339 to 0.02743, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 570s 993ms/step - loss: 0.0274 - accuracy: 0.9922 - val_loss: 0.0370 - val_accuracy: 0.9922\n",
            "Epoch 14/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9909\n",
            "Epoch 14: loss did not improve from 0.02743\n",
            "574/574 [==============================] - 528s 920ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.0465 - val_accuracy: 0.9877\n",
            "Epoch 15/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9915\n",
            "Epoch 15: loss did not improve from 0.02743\n",
            "574/574 [==============================] - 530s 922ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0325 - val_accuracy: 0.9926\n",
            "Epoch 16/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9913\n",
            "Epoch 16: loss did not improve from 0.02743\n",
            "574/574 [==============================] - 530s 923ms/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.0433 - val_accuracy: 0.9887\n",
            "Epoch 17/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9958\n",
            "Epoch 17: loss improved from 0.02743 to 0.01587, saving model to /content/drive/MyDrive/CS523_Deep_Learning\n",
            "574/574 [==============================] - 570s 993ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.0234 - val_accuracy: 0.9936\n",
            "Epoch 18/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9928\n",
            "Epoch 18: loss did not improve from 0.01587\n",
            "574/574 [==============================] - 529s 921ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.0699 - val_accuracy: 0.9819\n",
            "Epoch 19/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9948\n",
            "Epoch 19: loss did not improve from 0.01587\n",
            "574/574 [==============================] - 529s 921ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.0284 - val_accuracy: 0.9951\n",
            "Epoch 20/20\n",
            "574/574 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9940\n",
            "Epoch 20: loss did not improve from 0.01587\n",
            "574/574 [==============================] - 529s 920ms/step - loss: 0.0233 - accuracy: 0.9940 - val_loss: 0.0393 - val_accuracy: 0.9912\n"
          ]
        }
      ],
      "source": [
        "# Inception V3 model with fine tuning\n",
        "\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/CS523_Deep_Learning\", monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "history=model.fit(train_ds, epochs=20, validation_data=val_ds, callbacks=[checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YsdsjwZic0F4"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/CS523_Deep_Learning/Final_Net')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M6j3tCHqoQwG"
      },
      "outputs": [],
      "source": [
        "model=keras.models.load_model('/content/drive/MyDrive/CS523_Deep_Learning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8ydMIYCRa5Hw",
        "outputId": "7d85f9ca-25ba-4e36-c0a5-8d770ace2a50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efa559fe590>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plots\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s75qF-No8fpQ",
        "outputId": "f73cdfcd-e4a1-47c7-a7b9-2d7a2f4ad1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 91s 1s/step - loss: 0.9287 - accuracy: 0.8128\n",
            "0.8127785921096802\n"
          ]
        }
      ],
      "source": [
        "# Test Accuracy\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred and y_true for calculating metrics\n",
        "\n",
        "y_pred_t=model.predict(test_ds)\n",
        "y_pred=np.argmax(y_pred_t, axis=1)\n",
        "\n",
        "y_true = np.concatenate([y for x, y in test_ds], axis=0)"
      ],
      "metadata": {
        "id": "rqzL8CqqucZ8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 2 accuracy\n",
        "\n",
        "top_k_accuracy_score(y_true, y_pred_t, k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgrcXVpHkwzg",
        "outputId": "f8a23ffe-61d9-4b0c-f7c9-1ae9ca0616b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8781575037147102"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn-MsemB86Wh",
        "outputId": "d9ccab3f-3198-4d11-b3c3-13bb3aba2f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[148   6   0   8   1   0   0   1   3  47]\n",
            " [  0 160   3  17   0   0   6   0  36   2]\n",
            " [  1   0 186   0   0   0   1   0  28   5]\n",
            " [  5   2   0 211   0   0   0   0   0   2]\n",
            " [  0   4   0   7 200   0   1   0  11   0]\n",
            " [  0   0   0   0   0 226   0   0   0   0]\n",
            " [  0   0   0   0   6   0 192   0   5   0]\n",
            " [ 10   4   0   0   1   1   2  99  52   0]\n",
            " [ 16   0   0   4  21   3   1   1 106   7]\n",
            " [ 42   1   0   3   0   1   0   0   0 113]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "\n",
        "cm=confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtsdDoLuOWUE",
        "outputId": "d05a86f4-95be-49e5-affe-db7e410e91c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.812778603268945\n"
          ]
        }
      ],
      "source": [
        "# Precision\n",
        "\n",
        "print(precision_score(y_true,y_pred,average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ElKRuiCZ_0a",
        "outputId": "b07e01a8-b4ed-4757-bb6e-7fffae6ebe85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.812778603268945\n"
          ]
        }
      ],
      "source": [
        "# Recall\n",
        "\n",
        "print(recall_score(y_true,y_pred,average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmCjmujcaHi4",
        "outputId": "e4950f34-3493-487f-aa55-c23e73284dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.812778603268945\n"
          ]
        }
      ],
      "source": [
        "# F1 Score\n",
        "\n",
        "print(f1_score(y_true,y_pred,average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKyQW05Qcr0c",
        "outputId": "51312371-7231-4220-b9b0-eec54c34c8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.69      0.68       214\n",
            "           1       0.90      0.71      0.80       224\n",
            "           2       0.98      0.84      0.91       221\n",
            "           3       0.84      0.96      0.90       220\n",
            "           4       0.87      0.90      0.88       223\n",
            "           5       0.98      1.00      0.99       226\n",
            "           6       0.95      0.95      0.95       203\n",
            "           7       0.98      0.59      0.73       169\n",
            "           8       0.44      0.67      0.53       159\n",
            "           9       0.64      0.71      0.67       160\n",
            "\n",
            "    accuracy                           0.81      2019\n",
            "   macro avg       0.83      0.80      0.80      2019\n",
            "weighted avg       0.84      0.81      0.82      2019\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification Report \n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Inception_V3.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}